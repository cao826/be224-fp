{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206a30ec",
   "metadata": {},
   "source": [
    "# Running dataset with basic convolutional model\n",
    "\n",
    "If you want to see some basics about the data and the images, refer to the other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0193252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/basic-pytorch/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb72c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import data_handling as data\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c352c",
   "metadata": {},
   "source": [
    "## Creating dataset\n",
    "\n",
    "The code for this dataset is included in ```data_handling.py```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2617b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "needle_directory = '/Users/carlosolivares/be224-fp/data/NeedleImages/'\n",
    "labels_path = os.path.join(needle_directory, 'Labels.csv')\n",
    "\n",
    "data_transformer = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset = data.NeedleImageDataset(\n",
    "    path2data=needle_directory,\n",
    "    path2labels=labels_path,\n",
    "    transform = data_transformer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6872bb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train datset length: 504\n",
      "validation dataset length: 127\n"
     ]
    }
   ],
   "source": [
    "len_dataset = len(dataset)\n",
    "len_train = int(0.8 * len_dataset)\n",
    "len_val = len_dataset - len_train\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [len_train, len_val])\n",
    "\n",
    "print(\"train datset length:\", len(train_ds))\n",
    "print(\"validation dataset length:\", len(val_ds))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=10, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8605811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "## checking the length of the dataloaders\n",
    "print(len(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54bb2c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 512, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "checking to see that the batches come appropriately shaped for input to model. \n",
    "The model accepts data in (batch, channels, height, width)\n",
    "Our images are grayscale, so we stack the values to get 3 channels like an RGB\n",
    "\"\"\"\n",
    "\n",
    "for xb, yb in val_dl:\n",
    "    print(xb.shape)\n",
    "    print(yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb5a2f",
   "metadata": {},
   "source": [
    "## Model option 1\n",
    "\n",
    "This one has two output nodes with no output activation and ```torch.nn.CrossEntropyLoss``` as the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455bd2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "naivenet = model.NaiveNet()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d9c4c",
   "metadata": {},
   "source": [
    "### Training the model for ten epoch to see if it actually learns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e3d8462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-03.\n"
     ]
    }
   ],
   "source": [
    "weights = [.3027, .6973]\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='mean', weight=torch.tensor(weights))\n",
    "optimizer = optim.Adam(naivenet.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fbebc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of loss reduction on minibatch 10: 0.626650920510292\n",
      "Mean of loss reduction on minibatch 20: 0.5935717463493347\n",
      "Mean of loss reduction on minibatch 30: 0.6448981046676636\n",
      "Mean of loss reduction on minibatch 40: 0.7058503448963165\n",
      "Mean of loss reduction on minibatch 50: 0.9383671462535859\n",
      "Mean loss on epoch 1: 0.7068986454430748\n",
      "validation loss after epoch 1: 0.08548550296017504\n",
      "mean accuracy on validation set after epoch 1: 0.4131868131868131\n",
      "Adjusting learning rate of group 0 to 1.0000e-03.\n",
      "Mean of loss reduction on minibatch 10: 0.6949649810791015\n",
      "Mean of loss reduction on minibatch 20: 0.5787642538547516\n",
      "Mean of loss reduction on minibatch 30: 0.6483381152153015\n",
      "Mean of loss reduction on minibatch 40: 0.6382522404193878\n",
      "Mean of loss reduction on minibatch 50: 0.6466220319271088\n",
      "Mean loss on epoch 2: 0.641073514433468\n",
      "validation loss after epoch 2: 0.06507388484759594\n",
      "mean accuracy on validation set after epoch 2: 0.6714285714285714\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Mean of loss reduction on minibatch 10: 0.6234726965427398\n",
      "Mean of loss reduction on minibatch 20: 0.6346527516841889\n",
      "Mean of loss reduction on minibatch 30: 0.6293460428714752\n",
      "Mean of loss reduction on minibatch 40: 0.6299316883087158\n",
      "Mean of loss reduction on minibatch 50: 0.6280984580516815\n",
      "Mean loss on epoch 3: 0.6283389306535908\n",
      "validation loss after epoch 3: 0.06457761235124483\n",
      "mean accuracy on validation set after epoch 3: 0.6714285714285714\n",
      "Adjusting learning rate of group 0 to 1.0000e-04.\n",
      "Mean of loss reduction on minibatch 10: 0.6224266529083252\n",
      "Mean of loss reduction on minibatch 20: 0.6180802404880523\n",
      "Mean of loss reduction on minibatch 30: 0.6250485718250275\n",
      "Mean of loss reduction on minibatch 40: 0.6263190627098083\n",
      "Mean of loss reduction on minibatch 50: 0.6250116348266601\n",
      "Mean loss on epoch 4: 0.6231467536851472\n",
      "validation loss after epoch 4: 0.06409522585981474\n",
      "mean accuracy on validation set after epoch 4: 0.6714285714285714\n",
      "Adjusting learning rate of group 0 to 1.0000e-05.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "def train_on_epoch(model, dataloader, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    epoch_loss = 0\n",
    "    running_loss = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        inputs, labels = batch\n",
    "        new_loss = train_on_minibatch(\n",
    "            model = model,\n",
    "            inputs = inputs, \n",
    "            labels = labels,\n",
    "            loss_fn = loss_fn,\n",
    "            optimizer = optimizer\n",
    "        )\n",
    "        running_loss += new_loss\n",
    "        epoch_loss += new_loss\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print('Mean of loss reduction on minibatch {}: {}'.format(i+1, running_loss / 10.0))\n",
    "            #print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
    "            running_loss = 0.0\n",
    "    mean_loss = epoch_loss / float(len(dataloader))\n",
    "    return mean_loss\n",
    "\n",
    "\n",
    "def train_on_minibatch(model, inputs, labels, loss_fn, optimizer):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_fn(outputs, labels.to(torch.int64))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "for epoch in range(4):\n",
    "    mean_loss_on_epoch = model.train_on_epoch(\n",
    "        model = naivenet,\n",
    "        dataloader = train_dl,\n",
    "        loss_fn = criterion,\n",
    "        optimizer = optimizer\n",
    "    )\n",
    "    print('Mean loss on epoch {}: {}'.format((epoch+1), mean_loss_on_epoch))\n",
    "    val_loss = model.get_validation_loss(naivenet, criterion, val_dl)\n",
    "    print('validation loss after epoch {}: {}'.format((epoch+1), val_loss))\n",
    "    mean_accuracy = model.get_accuracy_on_dataloader(\n",
    "        model = naivenet,\n",
    "        dataloader = val_dl,\n",
    "        activation = torch.nn.Softmax(dim=1)\n",
    "    )\n",
    "    print('mean accuracy on validation set after epoch {}: {}'.format(epoch+1, mean_accuracy))\n",
    "    scheduler.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73865b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## how do we get an accuracy score? answer here\n",
    "\n",
    "for batch in val_dl:\n",
    "    inputs, labels = batch\n",
    "    outputs = naivenet(inputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7881ff09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/basic-pytorch/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4696, 0.5304],\n",
       "        [0.4512, 0.5488],\n",
       "        [0.4488, 0.5512],\n",
       "        [0.4491, 0.5509],\n",
       "        [0.4433, 0.5567],\n",
       "        [0.4499, 0.5501],\n",
       "        [0.4697, 0.5303],\n",
       "        [0.4554, 0.5446],\n",
       "        [0.4429, 0.5571],\n",
       "        [0.4467, 0.5533]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Softmax()(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10c730ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.nn.Softmax(dim=1)(outputs)\n",
    "print(probs.shape)\n",
    "classes = torch.argmax(probs, 1)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3c96f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4729, 0.5271],\n",
      "        [0.3009, 0.6991],\n",
      "        [0.7995, 0.2005],\n",
      "        [0.1875, 0.8125]])\n",
      "tensor([1, 1, 0, 1])\n",
      "tensor([ True,  True, False, False])\n",
      "2\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(4, 2)\n",
    "a = torch.nn.Softmax(dim=1)(a)\n",
    "print(a)\n",
    "print(torch.argmax(a, dim=1))\n",
    "labels = torch.Tensor([1, 1, 1, 0])\n",
    "print(torch.argmax(a, dim=1) == labels.to(torch.int64))\n",
    "print(sum(torch.argmax(a, dim=1) == labels.to(torch.int64)).item())\n",
    "print(a.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c461a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4aa3f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2826, 0.7174],\n",
      "        [0.1433, 0.8567],\n",
      "        [0.6965, 0.3035],\n",
      "        [0.5780, 0.4220]])\n",
      "tensor([1, 1, 0, 0])\n",
      "0.75\n"
     ]
    }
   ],
   "source": [
    "def get_accuracy(preds, labels, activation):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    probs = activation(preds)\n",
    "    classes = torch.argmax(probs, dim=1)\n",
    "    num_correct = sum(classes == labels).item()\n",
    "    num_examples = preds.shape[0]\n",
    "    return num_correct / float(num_examples)\n",
    "\n",
    "a = torch.randn(4, 2)\n",
    "a = torch.nn.Softmax(dim=1)(a)\n",
    "print(a)\n",
    "print(torch.argmax(a, dim=1))\n",
    "labels = torch.Tensor([1, 1, 1, 0])\n",
    "print(get_accuracy(a, labels, torch.nn.Softmax(dim=1)))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4c20976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 1., 0., 0., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## investigating how the crossentrupy loss works. From the docs: \n",
    "\n",
    "# Example of target with class indices\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "#output.backward()\n",
    "# Example of target with class probabilities\n",
    "#input = torch.randn(3, 5, requires_grad=True)\n",
    "#target = torch.randn(3, 5).softmax(dim=1)\n",
    "#output = loss(input, target)\n",
    "#output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de11edc7",
   "metadata": {},
   "source": [
    "### Looking at how the loss function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e57a794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6759, -0.8502,  0.7985, -0.5464,  1.2984],\n",
       "        [-1.1789, -1.6076, -0.6740,  1.3447, -0.6631],\n",
       "        [-1.3812,  0.5992,  2.3664,  0.8805,  0.3675]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0fe91c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5594c415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0512, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "491881a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4508,  0.3201],\n",
       "        [-0.4884,  0.3111],\n",
       "        [-0.4619,  0.3550],\n",
       "        [-0.5006,  0.3499]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d853cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9522da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7609, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31369730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb173171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next thing to do is actually get the metrics from model and stuff. \n",
    "# looks like you might need an lr schedulaer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a539e563",
   "metadata": {},
   "source": [
    "## Model option 2\n",
    "\n",
    "Same model but with one output node, sigmoid activation, and ```torch.nn.BCELoss```. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basic-pytorch]",
   "language": "python",
   "name": "conda-env-basic-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
