{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206a30ec",
   "metadata": {},
   "source": [
    "# Running dataset with basic convolutional model\n",
    "\n",
    "If you want to see some basics about the data and the images, refer to the other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0193252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb72c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import data_handling as data\n",
    "import model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c352c",
   "metadata": {},
   "source": [
    "## Creating dataset\n",
    "\n",
    "The code for this dataset is included in ```data_handling.py```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2617b3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "needle_directory = '/Users/carlosolivares/be224-fp/data/NeedleImages/'\n",
    "labels_path = os.path.join(needle_directory, 'Labels.csv')\n",
    "\n",
    "data_transformer = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "dataset = data.NeedleImageDataset(\n",
    "    path2data=needle_directory,\n",
    "    path2labels=labels_path,\n",
    "    transform = data_transformer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6872bb22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train datset length: 504\n",
      "validation dataset length: 127\n"
     ]
    }
   ],
   "source": [
    "len_dataset = len(dataset)\n",
    "len_train = int(0.8 * len_dataset)\n",
    "len_val = len_dataset - len_train\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [len_train, len_val])\n",
    "\n",
    "print(\"train datset length:\", len(train_ds))\n",
    "print(\"validation dataset length:\", len(val_ds))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=10, shuffle=True)\n",
    "val_dl = DataLoader(val_ds, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8605811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54bb2c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 512, 512])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "checking to see that the batches come appropriately shaped for input to model. \n",
    "The model accepts data in (batch, channels, height, width)\n",
    "Our images are grayscale, so we stack the values to get 3 channels like an RGB\n",
    "\"\"\"\n",
    "\n",
    "for xb, yb in val_dl:\n",
    "    print(xb.shape)\n",
    "    print(yb.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb5a2f",
   "metadata": {},
   "source": [
    "## Getting model working\n",
    "\n",
    "ummm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "455bd2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "naivenet = model.NaiveNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "725b1135",
   "metadata": {},
   "outputs": [],
   "source": [
    "for xb, yb in val_dl:\n",
    "    out = naivenet(xb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b63ef40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2d9c4c",
   "metadata": {},
   "source": [
    "## Training the model for two epoch to see if it actually learns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e3d8462",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "optimizer = optim.SGD(naivenet.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fbebc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    10] loss: 6.717\n",
      "[1,    20] loss: 6.236\n",
      "[1,    30] loss: 6.087\n",
      "[1,    40] loss: 6.721\n",
      "[1,    50] loss: 6.269\n",
      "validation loss after epoch 51: 0.6045545048601045\n",
      "[2,    10] loss: 6.422\n",
      "[2,    20] loss: 5.959\n",
      "[2,    30] loss: 6.286\n",
      "[2,    40] loss: 5.813\n",
      "[2,    50] loss: 6.450\n",
      "validation loss after epoch 51: 0.6030995714382863\n",
      "[3,    10] loss: 6.042\n",
      "[3,    20] loss: 5.014\n",
      "[3,    30] loss: 6.449\n",
      "[3,    40] loss: 6.890\n",
      "[3,    50] loss: 6.517\n",
      "validation loss after epoch 51: 0.6068611501708744\n",
      "[4,    10] loss: 5.790\n",
      "[4,    20] loss: 6.106\n",
      "[4,    30] loss: 5.782\n",
      "[4,    40] loss: 6.559\n",
      "[4,    50] loss: 6.631\n",
      "validation loss after epoch 51: 0.6050305629339744\n",
      "[5,    10] loss: 5.819\n",
      "[5,    20] loss: 6.350\n",
      "[5,    30] loss: 6.349\n",
      "[5,    40] loss: 6.502\n",
      "[5,    50] loss: 5.756\n",
      "validation loss after epoch 51: 0.6048059576139675\n",
      "[6,    10] loss: 6.352\n",
      "[6,    20] loss: 6.135\n",
      "[6,    30] loss: 6.121\n",
      "[6,    40] loss: 6.124\n",
      "[6,    50] loss: 6.190\n",
      "validation loss after epoch 51: 0.6040606968046174\n",
      "[7,    10] loss: 6.193\n",
      "[7,    20] loss: 6.127\n",
      "[7,    30] loss: 6.035\n",
      "[7,    40] loss: 5.773\n",
      "[7,    50] loss: 6.632\n",
      "validation loss after epoch 51: 0.6040854266309362\n",
      "[8,    10] loss: 6.447\n",
      "[8,    20] loss: 5.811\n",
      "[8,    30] loss: 6.268\n",
      "[8,    40] loss: 6.121\n",
      "[8,    50] loss: 6.201\n",
      "validation loss after epoch 51: 0.6040114023554044\n",
      "[9,    10] loss: 5.868\n",
      "[9,    20] loss: 5.602\n",
      "[9,    30] loss: 6.485\n",
      "[9,    40] loss: 6.560\n",
      "[9,    50] loss: 6.199\n",
      "validation loss after epoch 51: 0.6048696041107178\n",
      "[10,    10] loss: 6.202\n",
      "[10,    20] loss: 5.969\n",
      "[10,    30] loss: 6.171\n",
      "[10,    40] loss: 6.024\n",
      "[10,    50] loss: 6.363\n",
      "validation loss after epoch 51: 0.6028665557621032\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        naivenet.train()\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = naivenet(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 10:.3f}')\n",
    "            running_loss = 0.0\n",
    "    val_loss = model.get_validation_loss(naivenet, criterion, val_dl)\n",
    "    print('validation loss after epoch {}: {}'.format((i+1), val_loss))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73865b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Ok, it seems to be working, so now all we need is to figure out exactly how to get metrics and loss or whatever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eca3836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## investigating how the crossentrupy loss works. From the docs: \n",
    "\n",
    "# Example of target with class indices\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(input, target)\n",
    "#output.backward()\n",
    "# Example of target with class probabilities\n",
    "#input = torch.randn(3, 5, requires_grad=True)\n",
    "#target = torch.randn(3, 5).softmax(dim=1)\n",
    "#output = loss(input, target)\n",
    "#output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e57a794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6759, -0.8502,  0.7985, -0.5464,  1.2984],\n",
       "        [-1.1789, -1.6076, -0.6740,  1.3447, -0.6631],\n",
       "        [-1.3812,  0.5992,  2.3664,  0.8805,  0.3675]], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0fe91c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5594c415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0512, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "491881a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4508,  0.3201],\n",
       "        [-0.4884,  0.3111],\n",
       "        [-0.4619,  0.3550],\n",
       "        [-0.5006,  0.3499]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d853cbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d9522da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7609, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "31369730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dl.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb173171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the next thing to do is actually get the metrics from model and stuff. \n",
    "# looks like you might need an lr schedulaer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:basic-pytorch]",
   "language": "python",
   "name": "conda-env-basic-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
